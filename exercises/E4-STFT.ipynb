{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2cgipUTb3jW"
   },
   "source": [
    "# Exercise 4: Short-time Fourier Transform\n",
    "\n",
    "Doing this exercise you will learn about the concept of the main lobe width of the spectrum of a window and you will better understand the short-time Fourier transform (STFT). You will also use the STFT to extract basic rhythm related information from an audio signal, implementing an onset detection function, which is one of the rhythm descriptors often used in music information retrieval to detect onsets of acoustic events.\n",
    "\n",
    "There are four parts in this exercise. 1) Extracting the main lobe of the spectrum of a window, 2) Measuring noise in the reconstructed signal using the STFT model, 3) Computing band-wise energy envelopes of a signal, 4) Computing an onset detection function.\n",
    "\n",
    "\n",
    "### Relevant Concepts\n",
    "\n",
    "__Main lobe of the spectrum of a window:__\n",
    "The width of the main lobe of the magnitude spectrum of a window is an important characteristic used in deciding which window type is best for the analysis of an audio excerpt. There exists a tradeoff between the main lobe width and the side lobe attenuation. Typically for windows with a narrower main lobe, the side lobes are less attenuated.\n",
    "An interesting fact is that changing the length of a window $M$ doesn't affect the main lobe width of the spectrum of the window in samples. Note that if you use zero-padding for computing the spectrum of a window, the main lobe width will be multiplied by the zero-padding factor.\n",
    "\n",
    "__Fast Fourier Transform (FFT):__\n",
    "An efficient way to compute the discrete Fourier transform of a signal is the fast Fourier transform, FFT. The FFT algorithm  factorizes the DFT matrix in order to exploit the symmetries in the DFT equation. FFT computation is specially very efficient when the FFT size is a power of 2. Therefore, whenever possible we use an FFT size that is a power of 2.\n",
    "\n",
    "__Energy of a signal:__ The energy of a signal $x[n]$ of length $N$ can be computed in the discrete time domain as follows:\n",
    "\\begin{equation}\n",
    "E=\\overset{N-1}{\\underset{n=0}{\\sum}}\\left|x\\left[n\\right]\\right|^{2}\n",
    "\\end{equation}\n",
    "\n",
    "__Energy in a frequency band:__ Given the DFT spectrum of the signal $X[k]$, the energy $E$ in a specific frequency band spanning the bin index $k_1$ to $k_2$ can be computed as:\n",
    "\n",
    "\\begin{equation}\n",
    "E=\\overset{k_{2}}{\\underset{k=k_{1}}{\\sum}}\\left|X\\left[k\\right]\\right|^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Note that in this computation the $X[k]$ values are not in decibels (dB). The `stftAnal()` function returns magnitude spectra in dB scale, which should be converted to linear scale before the energy computation. Once the energy is computed it can be converted back to the dB scale as:\n",
    "\n",
    "\\begin{equation}\n",
    "E_{dB}= 10\\,\\log_{10}(E)\n",
    "\\end{equation}\n",
    "\n",
    "__Signal to noise ratio (SNR):__\n",
    "Signal to noise ratio (SNR) is a frequently used measure to quantify the amount of noise present/added in a signal. In the context of this exercise it can be computed in decibels (dB) as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{SNR} = 10\\,\\log_{10}\\left(\\frac{E_{\\mathrm{signal}}}{E_{\\mathrm{noise}}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "where, $E_{\\mathrm{signal}}$ and $E_{\\mathrm{noise}}$ are the energy of the signal and noise respectively.\n",
    "\n",
    "For our case of analysis and synthesis using a specific model (for example, STFT) noise can be thought of as the difference between the input signal and the output signal of the model.\n",
    "\n",
    "__Onset detection function:__\n",
    "An onset detection function (ODF) refers to a continuous function (one value per audio frame) often used for detecting acoustic events in an audio stream. In music information retrieval (MIR), ODFs are typically used for detecting onsets of musical notes and percussion strokes. An ODF generally has high values at the onsets of acoustic events. A simple ODF can be computed by taking the difference between the energy values of consecutive frames, as shown below:\n",
    "\n",
    "\\begin{equation}\n",
    "O(l) = E(l) - E(l-1) ,\\,\\,\\,\\,\\, l \\geq 1\n",
    "\\end{equation}\n",
    "\n",
    "where, $O(l)$ is the ODF computed at frame index $l$ and $E$ is the energy of the signal in a particular frequency band in decibels (dB). Often, multiple ODFs are computed with different frequency bands across the spectrum.\n",
    "\n",
    "In order to detect only the onsets of the events and not the offsets, it is a common practice to half wave rectify the ODF and obtain $\\bar{O}(l)$. Half wave rectification of the ODF is given by:\n",
    "\n",
    " \\begin{equation}\n",
    " \\bar{O}(l)=\\begin{cases}\n",
    " \\begin{array}{c}\n",
    " O(l), \\, \\mathrm{if} \\,\\,O(l)>0\\\\\n",
    " \\,\\,\\,\\,0, \\,\\,\\,\\,\\, \\mathrm{if} \\,\\, O(l)\\leq0\n",
    " \\end{array}\\end{cases}\n",
    " \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDRjhlEbb3jY"
   },
   "source": [
    "## Part 1 - Extracting the main lobe of the spectrum of a window\n",
    "\n",
    "The function `extract_main_lobe()` should extract the main lobe of the magnitude spectrum of a window given a window type, `window`, and its length, `M`. The function should return the samples corresponding to the main lobe in decibels (dB).\n",
    "\n",
    "To compute the spectrum you should take the FFT size (`N`) to be 8 times the window length (`N = 8*M`) (For this part, `N` does not need to be a power of 2).\n",
    "\n",
    "The input arguments to the function are the window type (`window`) and the length of the window (`M`). The function should return a numpy array containing the samples corresponding to the main lobe of the window. In the returned numpy array you should include the samples corresponding to both the local minimas across the main lobe.\n",
    "\n",
    "The possible window types that you can expect as input are rectangular (`'boxcar'`), `'hamming'` or `'blackmanharris'`.\n",
    "\n",
    "NOTE: You can approach this task by writing code to find the indices of the local minimas across the main lobe.\n",
    "\n",
    "_Tip:_ `log10(0)` is not well defined, so its a common practice to add a small value such as `eps = 1e-16` to the magnitude spectrum before computing it in dB. This is optional and will not affect your answers.\n",
    "If you find it difficult to concatenate the two halves of the main lobe, you can first center the spectrum using `fftshift()` and then compute the indexes of the minimas around the main lobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CJEsS-8Hb3jZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import get_window\n",
    "from scipy.fftpack import fft, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.finfo(float).eps\n",
    "from smstools.models import stft\n",
    "from smstools.models import utilFunctions as UF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PTqbW4Z1b3jZ"
   },
   "outputs": [],
   "source": [
    "def extract_main_lobe(window, M):\n",
    "    w = get_window(window, M)\n",
    "    N = 8 * M\n",
    "    W = fft(w, N)\n",
    "    mW = 20 * np.log10(np.abs(W) + eps)\n",
    "    mW = fftshift(mW)\n",
    "    mid = int(N / 2)\n",
    "    left_min = np.where(mW[:mid] == np.min(mW[:mid]))[0][0]\n",
    "    right_min = np.where(mW[mid:] == np.min(mW[mid:]))[0][0] + mid\n",
    "    main_lobe = mW[left_min:right_min + 1]\n",
    "    return main_lobe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zyHg2XTb3jZ"
   },
   "source": [
    "Test cases for the function `extract_main_lobe()`:\n",
    "\n",
    "_Test case 1:_ If you run your code using `window = 'blackmanharris'`, `M = 100` and `N = 800`, the output numpy array should contain 65 samples.\n",
    "\n",
    "_Test case 2:_ If you run your code using `window = 'boxcar'`, `M = 120` and `N = 960`, the output numpy array should contain 17 samples.\n",
    "\n",
    "_Test case 3:_ If you run your code using `window = 'hamming`, `M = 256`, and `N = 2048`, the output numpy array should contain 33 samples.\n",
    "\n",
    "To understand better the result you can plot the magnitude spectrum of the window and mark the boundaries of the main lobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jJbOGahob3jZ"
   },
   "outputs": [],
   "source": [
    "window = 'blackmanharris'\n",
    "M = 100\n",
    "main_lobe = extract_main_lobe(window, M)\n",
    "plt.plot(main_lobe)\n",
    "plt.title('Main lobe of blackmanharris window, M=100')\n",
    "plt.show()\n",
    "\n",
    "window = 'boxcar'\n",
    "M = 120\n",
    "main_lobe = extract_main_lobe(window, M)\n",
    "plt.plot(main_lobe)\n",
    "plt.title('Main lobe of boxcar window, M=120')\n",
    "plt.show()\n",
    "\n",
    "window = 'hamming'\n",
    "M = 256\n",
    "main_lobe = extract_main_lobe(window, M)\n",
    "plt.plot(main_lobe)\n",
    "plt.title('Main lobe of hamming window, M=256')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAMfh9fab3ja"
   },
   "source": [
    "## Part 2 - Measuring noise in the reconstructed signal using the STFT model\n",
    "\n",
    "The function `compute_snr()` should measure the amount of distortion introduced during the analysis and synthesis of a signal using the STFT model. Use SNR (signal to noise ratio) in dB to quantify the amount of noise.\n",
    "Use the `stft()` function in `stft.py` to do an analysis followed by a synthesis of the input signal.\n",
    "\n",
    "Use the time domain energy definition to compute the SNR. With the input signal and the obtained output, compute two different SNR values for the following cases:\n",
    "\n",
    "1. `SNR1`: Over the entire length of the input and the output signals.\n",
    "2. `SNR2`: For the segment of the signals left after discarding `M` samples from both the start and the end, where `M` is the analysis window length.\n",
    "\n",
    "Note that the computations are done after STFT analysis and synthesis. The input arguments to the function are the wav file name including the path (`input_file`), window  type (`window`), window length (`M`), FFT size (`N`), and hop size (`H`). The function should return a python tuple of both the SNR values in decibels. Both SNR1 and SNR2 are float values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0VaVcTDFb3ja"
   },
   "outputs": [],
   "source": [
    "def compute_snr(input_file, window, M, N, H):\n",
    "    fs, x = UF.wavread(input_file)\n",
    "    w = get_window(window, M)\n",
    "    mX, pX = stft.stftAnal(x, w, N, H)\n",
    "    y = stft.stftSynth(mX, pX, M, H)\n",
    "    E_signal = np.sum(x ** 2)\n",
    "    E_noise = np.sum((x - y) ** 2)\n",
    "    SNR1 = 10 * np.log10(E_signal / E_noise)\n",
    "    x_trimmed = x[M:-M]\n",
    "    y_trimmed = y[M:-M]\n",
    "    E_signal_trimmed = np.sum(x_trimmed ** 2)\n",
    "    E_noise_trimmed = np.sum((x_trimmed - y_trimmed) ** 2)\n",
    "    SNR2 = 10 * np.log10(E_signal_trimmed / E_noise_trimmed)\n",
    "    return (SNR1, SNR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PqUt9fJb3ja"
   },
   "source": [
    "Test cases for the function `compute_snr()`:\n",
    "\n",
    "_Test case 1:_ If you run your code using `piano.wav` file with `'blackman'` window, `M = 513`, `N = 2048` and\n",
    "`H = 128`, the output SNR values should be around: `(67.57748352378475, 86.35716169253175)`.\n",
    "\n",
    "_Test case 2:_ If you run your code using `sax-phrase-short.wav` file with `'hamming'` window, `M = 512`,\n",
    "`N = 1024` and `H = 64`, the output SNR values should be around: `(89.510506656299285, 306.18696700251388)`.\n",
    "\n",
    "_Test case 3:_ If you run your code using `rain.wav` file with `'hann'` window, `M = 1024`, `N = 2048` and\n",
    "`H = 128`, the output SNR values should be around: `(74.631476225366825, 304.26918192997738)`.\n",
    "\n",
    "Due to precision differences on different machines/hardware, compared to the expected SNR values, your output values can differ substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S7FbpxR1b3ja"
   },
   "outputs": [],
   "source": [
    "input_file = '../sounds/piano.wav'\n",
    "window = 'blackman'\n",
    "M = 513\n",
    "N = 2048\n",
    "H = 128\n",
    "SNR1, SNR2 = compute_snr(input_file, window, M, N, H)\n",
    "print(f'SNR1: {SNR1}, SNR2: {SNR2}')\n",
    "\n",
    "input_file = '../sounds/sax-phrase-short.wav'\n",
    "window = 'hamming'\n",
    "M = 512\n",
    "N = 1024\n",
    "H = 64\n",
    "SNR1, SNR2 = compute_snr(input_file, window, M, N, H)\n",
    "print(f'SNR1: {SNR1}, SNR2: {SNR2}')\n",
    "\n",
    "input_file = '../sounds/rain.wav'\n",
    "window = 'hann'\n",
    "M = 1024\n",
    "N = 2048\n",
    "H = 128\n",
    "SNR1, SNR2 = compute_snr(input_file, window, M, N, H)\n",
    "print(f'SNR1: {SNR1}, SNR2: {SNR2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O52fQHmNb3ja"
   },
   "source": [
    "## Part 3 - Computing band-wise energy envelopes of a signal\n",
    "\n",
    "The function `compute_eng_env()` should compute band-wise energy envelopes of a given audio signal using the STFT.\n",
    "\n",
    "Consider two frequency bands, low and high. The low frequency band is the set of frequencies between 0 and 3000 Hz and the high frequency band is the set of frequencies between 3000 and 10000 Hz (excluding the boundary frequencies in both the cases). At a given frame, the value of the energy envelope of a band can be computed as the sum of squared values of all the frequency coefficients in that band. Then you should compute the energy envelopes in decibels.\n",
    "\n",
    "The input arguments are the wav file name including the path (`input_file`), window type (`window`), window length (`M`), FFT size (`N`) and hop size (`H`). The function should return a numpy array with two columns, where the first column is the energy envelope of the low frequency band and the second column is that of the high frequency band.\n",
    "\n",
    "Use `stftAnal()` function from `stft.py` module to obtain the magnitude spectra for all the audio frames of the input sound. Then compute the energy values for each frequency band specified. While calculating frequency bins for each frequency band, consider only the bins that are within the specified frequency range. For example, for the low frequency band consider only the bins with frequency > 0 Hz and < 3000 Hz (you can use `np.where()` to find those bin indexes). This way you also remove the DC offset of the signal in energy envelope computation. The frequency corresponding to the bin index `k` can be computed as `k*fs/N`, where `fs` is the sampling rate of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lE3m7CUeb3jb"
   },
   "outputs": [],
   "source": [
    "def compute_eng_env(input_file, window, M, N, H):\n",
    "    fs, x = UF.wavread(input_file)\n",
    "    w = get_window(window, M)\n",
    "    mX, pX = stft.stftAnal(x, w, N, H)\n",
    "    bin_freqs = np.arange(N) * fs / N\n",
    "    low_band_bins = np.where((bin_freqs > 0) & (bin_freqs < 3000))[0]\n",
    "    high_band_bins = np.where((bin_freqs > 3000) & (bin_freqs < 10000))[0]\n",
    "    low_band_energy = 10 * np.log10(np.sum(10 ** (mX[:, low_band_bins] / 10), axis=1) + eps)\n",
    "    high_band_energy = 10 * np.log10(np.sum(10 ** (mX[:, high_band_bins] / 10), axis=1) + eps)\n",
    "    energy_envelopes = np.column_stack((low_band_energy, high_band_energy))\n",
    "    return energy_envelopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKpvZREFb3jb"
   },
   "source": [
    "Test cases for the function `compute_eng_env()`:\n",
    "\n",
    "_Test case 1:_ Use `piano.wav` file with `window = 'blackman'`, `M = 513`, `N = 1024` and `H = 128` as input.\n",
    "The bin indexes of the low frequency band span from 1 to 69 (69 samples) and of the high frequency\n",
    "band span from 70 to 232 (163 samples).\n",
    "\n",
    "_Test case 2:_ Use `piano.wav` file with `window = 'blackman'`, `M = 2047`, `N = 4096` and `H = 128` as input.\n",
    "The bin indexes of the low frequency band span from 1 to 278 (278 samples) and of the high frequency\n",
    "band span from 279 to 928 (650 samples).\n",
    "\n",
    "_Test case 3:_ Use `sax-phrase-short.wav` file with `window = 'hamming'`, `M = 513`, `N = 2048` and `H = 256` as\n",
    "input. The bin indexes of the low frequency band span from 1 to 139 (139 samples) and of the high\n",
    "frequency band span from 140 to 464 (325 samples).\n",
    "\n",
    "To get a better understanding of the band-wise energy envelope and its characteristics you can plot the envelopes together with the spectrogram of the signal. You can use `matplotlib` plotting library for this purpose. To visualize the spectrogram of a signal, a good option is to use the function `colormesh()` (you can reuse the code in\n",
    "`lectures/4-STFT/plots-code/spectrogram.py`). Either overlay the envelopes on the spectrogram\n",
    "or plot them in a different subplot. Make sure you use the same range of the x-axis for both the spectrogram and the energy envelopes.\n",
    "\n",
    "You can clearly notice the sharp attacks and decay of the piano notes for test case 1. You can compare this with the output from test case 2 that uses a larger window. You can infer the influence of window size on sharpness of the note attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yow102onb3jb"
   },
   "outputs": [],
   "source": [
    "input_file = '../sounds/piano.wav'\n",
    "window = 'blackman'\n",
    "M = 513\n",
    "N = 1024\n",
    "H = 128\n",
    "energy_envelopes = compute_eng_env(input_file, window, M, N, H)\n",
    "fs, x = UF.wavread(input_file)\n",
    "mX, pX = stft.stftAnal(x, get_window(window, M), N, H)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(np.arange(x.size) / float(fs), x)\n",
    "plt.axis([0, x.size / float(fs), min(x), max(x)])\n",
    "plt.ylabel('amplitude')\n",
    "plt.xlabel('time (sec)')\n",
    "plt.title('input sound: x')\n",
    "plt.subplot(3, 1, 2)\n",
    "numFrames = int(mX[:, 0].size)\n",
    "frmTime = H * np.arange(numFrames) / float(fs)\n",
    "binFreq = fs * np.arange(N * 5000.0 / fs) / N\n",
    "plt.pcolormesh(frmTime, binFreq, np.transpose(mX[:, : int(N * 5000.0 / fs + 1)]))\n",
    "plt.xlabel('time (sec)')\n",
    "plt.ylabel('frequency (Hz)')\n",
    "plt.title('magnitude spectrogram')\n",
    "plt.autoscale(tight=True)\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(frmTime, energy_envelopes[:, 0], label='Low frequency band')\n",
    "plt.plot(frmTime, energy_envelopes[:, 1], label='High frequency band')\n",
    "plt.xlabel('time (sec)')\n",
    "plt.ylabel('energy (dB)')\n",
    "plt.title('Energy envelopes')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdzFA8plb3jb"
   },
   "source": [
    "## Part 4 - Computing onset detection function\n",
    "\n",
    "The function `compute_odf()` should compute a simple onset detection function (ODF) using the STFT. It should compute two ODFs one for each of the frequency bands, low and high. The low frequency band is the set of all the frequencies between 0 and 3000 Hz and the high frequency band is the set of all the frequencies between 3000 and 10000 Hz (excluding the boundary frequencies in both the cases).\n",
    "\n",
    "Start with an initial condition of `ODF(0) = 0` in order to make the length of the ODF same as that of the energy envelope. Remember to apply a half wave rectification on the ODF.\n",
    "\n",
    "The input arguments to the function are the wav file name including the path (`input_file`), window\n",
    "type (`window`), window length (`M`), FFT size (`N`), and hop size (`H`). The function should return a numpy\n",
    "array with two columns, where the first column is the ODF computed on the low frequency band and the\n",
    "second column is the ODF computed on the high frequency band.\n",
    "\n",
    "Use `stftAnal()` to obtain the magnitude spectra for all the audio frames. Then compute the band-wise energy envelope for each frequency band specified. Finally compute the half wave rectify version of ODF from each energy envelope.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Svo7SmY2b3jb"
   },
   "outputs": [],
   "source": [
    "def compute_odf(input_file, window, M, N, H):\n",
    "    fs, x = UF.wavread(input_file)\n",
    "    w = get_window(window, M)\n",
    "    mX, pX = stft.stftAnal(x, w, N, H)\n",
    "    bin_freqs = np.arange(N) * fs / N\n",
    "    low_band_bins = np.where((bin_freqs > 0) & (bin_freqs < 3000))[0]\n",
    "    high_band_bins = np.where((bin_freqs > 3000) & (bin_freqs < 10000))[0]\n",
    "    low_band_energy = 10 * np.log10(np.sum(10 ** (mX[:, low_band_bins] / 10), axis=1) + eps)\n",
    "    high_band_energy = 10 * np.log10(np.sum(10 ** (mX[:, high_band_bins] / 10), axis=1) + eps)\n",
    "    low_band_odf = np.diff(np.concatenate(([0], low_band_energy)))\n",
    "    high_band_odf = np.diff(np.concatenate(([0], high_band_energy)))\n",
    "    low_band_odf = np.maximum(low_band_odf, 0)\n",
    "    high_band_odf = np.maximum(high_band_odf, 0)\n",
    "    odf = np.column_stack((low_band_odf, high_band_odf))\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uFHenX4b3jb"
   },
   "source": [
    "Test cases for the function `compute_odf()`:\n",
    "\n",
    "_Test case 1:_ Use `piano.wav` file with `window = 'blackman'`, `M = 513`, `N = 1024` and `H = 128` as input.\n",
    "The bin indexes of the low frequency band span from 1 to 69 (69 samples) and of the high frequency\n",
    "band span from 70 to 232 (163 samples).\n",
    "\n",
    "_Test case 2:_ Use `piano.wav` file with `window = 'blackman'`, `M = 2047`, `N = 4096` and `H = 128` as input.\n",
    "The bin indexes of the low frequency band span from 1 to 278 (278 samples) and of the high frequency\n",
    "band span from 279 to 928 (650 samples).\n",
    "\n",
    "_Test case 3:_ Use `sax-phrase-short.wav` file with `window = 'hamming'`, `M = 513`, `N = 2048` and `H = 256` as\n",
    "input. The bin indexes of the low frequency band span from 1 to 139 (139 samples) and of the high\n",
    "frequency band span from 140 to 464 (325 samples).\n",
    "\n",
    "To get a better understanding of the ODFs and their characteristics you can plot the ODF functions together with the spectrogram of the signal. Use the same plotting than in the previos part.\n",
    "\n",
    "In order to identify the actual onsets of a signal you would need to find the peaks, local maxima, of the ODF functions using a magnitude threshold. Which of the 2 ODFs (low or high frequencies) would be most useful? What would be the right threshold for all 3 cases? Could you find a single threshold to be used for all 3 cases?\n",
    "\n",
    "For test case 1, you should clearly see that the ODFs have sharp peaks at the onset of the piano notes. You should notice 5 peaks that are above 10dB value in the ODF computed on the high frequency band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BJsLOTs3b3jb"
   },
   "outputs": [],
   "source": [
    "input_file = '../sounds/piano.wav'\n",
    "window = 'blackman'\n",
    "M = 513\n",
    "N = 1024\n",
    "H = 128\n",
    "odf = compute_odf(input_file, window, M, N, H)\n",
    "fs, x = UF.wavread(input_file)\n",
    "mX, pX = stft.stftAnal(x, get_window(window, M), N, H)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(np.arange(x.size) / float(fs), x)\n",
    "plt.axis([0, x.size / float(fs), min(x), max(x)])\n",
    "plt.ylabel('amplitude')\n",
    "plt.xlabel('time (sec)')\n",
    "plt.title('input sound: x')\n",
    "plt.subplot(3, 1, 2)\n",
    "numFrames = int(mX[:, 0].size)\n",
    "frmTime = H * np.arange(numFrames) / float(fs)\n",
    "binFreq = fs * np.arange(N * 5000.0 / fs) / N\n",
    "plt.pcolormesh(frmTime, binFreq, np.transpose(mX[:, : int(N * 5000.0 / fs + 1)]))\n",
    "plt.xlabel('time (sec)')\n",
    "plt.ylabel('frequency (Hz)')\n",
    "plt.title('magnitude spectrogram')\n",
    "plt.autoscale(tight=True)\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(frmTime, odf[:, 0], label='Low frequency band')\n",
    "plt.plot(frmTime, odf[:, 1], label='High frequency band')\n",
    "plt.xlabel('time (sec)')\n",
    "plt.ylabel('ODF (dB)')\n",
    "plt.title('Onset Detection Function')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZecHFWkrclac"
   },
   "source": [
    "**Questions E4 - 4.3:**\n",
    "\n",
    "#### Explain the results of Part 4"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
